"""
œÄ NORMALITY PROOF/DISPROOF SCRIPT
Using Continued Fraction Analysis and Error Distribution

Based on the discovery that œÄ's digits encode rational approximation errors,
this script tests whether œÄ is normal by analyzing the structure of these errors.
"""

import math
from decimal import Decimal, getcontext
from fractions import Fraction
from collections import Counter
import sys

# Set ultra-high precision
getcontext().prec = 100050

class PiNormalityTester:
    def __init__(self, pi_file='pi_digits.txt', num_digits=100000):
        print("‚ïî" + "‚ïê" * 78 + "‚ïó")
        print("‚ïë" + " " * 15 + "œÄ NORMALITY PROOF/DISPROOF ENGINE" + " " * 30 + "‚ïë")
        print("‚ïö" + "‚ïê" * 78 + "‚ïù\n")
        
        self.num_digits = num_digits
        self.pi_str = self.read_pi_digits(pi_file, num_digits)
        self.pi_decimal = Decimal('3.' + self.pi_str)
        self.cf_terms = []
        self.convergents = []
        
        print(f"‚úì Loaded {len(self.pi_str)} digits of œÄ\n")
    
    def read_pi_digits(self, filename, num_digits):
        """Read œÄ digits from file"""
        with open(filename, 'r') as f:
            content = f.read(num_digits + 100)
        
        content = content.replace('\n', '').replace(' ', '').replace('\r', '').replace('\t', '')
        
        if content.startswith('3.'):
            content = content[2:]
        elif content.startswith('3'):
            content = content[1:]
        
        return content[:num_digits]
    
    def compute_continued_fraction(self, max_terms=100):
        """Compute continued fraction terms"""
        print("üî¢ Computing continued fraction terms...")
        
        terms = []
        x = self.pi_decimal
        
        for i in range(max_terms):
            a = int(x)
            terms.append(a)
            x = x - a
            if x < Decimal('1e-100'):
                break
            x = 1 / x
            
            if i < 30 or a > 10:
                print(f"  CF[{i:3}] = {a:6}")
        
        self.cf_terms = terms
        print(f"\n‚úì Computed {len(terms)} CF terms\n")
        return terms
    
    def get_convergent(self, n):
        """Calculate nth convergent"""
        if n == 0:
            return Fraction(self.cf_terms[0], 1)
        
        h_prev2, h_prev1 = 1, self.cf_terms[0]
        k_prev2, k_prev1 = 0, 1
        
        for i in range(1, min(n + 1, len(self.cf_terms))):
            h = self.cf_terms[i] * h_prev1 + h_prev2
            k = self.cf_terms[i] * k_prev1 + k_prev2
            h_prev2, h_prev1 = h_prev1, h
            k_prev2, k_prev1 = k_prev1, k
        
        return Fraction(h_prev1, k_prev1)
    
    def compute_all_convergents(self):
        """Compute all convergents"""
        print("üìä Computing convergents...")
        
        self.convergents = []
        for i in range(len(self.cf_terms)):
            conv = self.get_convergent(i)
            self.convergents.append(conv)
            
            if i < 20 or self.cf_terms[i] > 10:
                conv_decimal = Decimal(conv.numerator) / Decimal(conv.denominator)
                error = abs(self.pi_decimal - conv_decimal)
                print(f"  Convergent {i:3}: {conv.numerator}/{conv.denominator} (error: {error:.2e})")
        
        print(f"\n‚úì Computed {len(self.convergents)} convergents\n")
    
    def chi_square_test(self, digits_str, expected_freq=None):
        """Perform chi-square test for uniformity"""
        if expected_freq is None:
            expected_freq = len(digits_str) / 10
        
        counts = Counter(digits_str)
        chi_square = 0
        
        for digit in '0123456789':
            observed = counts.get(digit, 0)
            chi_square += (observed - expected_freq) ** 2 / expected_freq
        
        return chi_square
    
    def test_1_baseline_digit_distribution(self):
        """TEST 1: Baseline - Are œÄ's digits uniformly distributed?"""
        print("=" * 80)
        print("TEST 1: BASELINE DIGIT DISTRIBUTION")
        print("=" * 80)
        
        # Test different windows
        windows = [1000, 10000, 50000, len(self.pi_str)]
        results = []
        
        for window in windows:
            if window > len(self.pi_str):
                continue
            
            test_str = self.pi_str[:window]
            chi_sq = self.chi_square_test(test_str)
            
            # Count digits
            counts = Counter(test_str)
            
            print(f"\nWindow: First {window:,} digits")
            print(f"Chi-square: {chi_sq:.4f}")
            print(f"Threshold:  16.919 (95% confidence)")
            print(f"Result: {'‚úì UNIFORM' if chi_sq < 16.919 else '‚úó NON-UNIFORM'}")
            
            # Show distribution
            print("\nDigit distribution:")
            expected = window / 10
            for digit in '0123456789':
                count = counts.get(digit, 0)
                deviation = count - expected
                pct = (count / window) * 100
                bar = '‚ñà' * int(pct)
                print(f"  {digit}: {count:5} ({pct:5.2f}%) {bar:12} | deviation: {deviation:+6.1f}")
            
            results.append({
                'window': window,
                'chi_square': chi_sq,
                'uniform': chi_sq < 16.919
            })
        
        # Verdict
        print("\n" + "‚îÄ" * 80)
        all_uniform = all(r['uniform'] for r in results)
        print(f"VERDICT: œÄ's digits appear {'UNIFORM' if all_uniform else 'NON-UNIFORM'} (baseline)")
        print("‚îÄ" * 80 + "\n")
        
        return results
    
    def test_2_convergent_error_distribution(self):
        """TEST 2: CRITICAL - Are convergent errors uniformly distributed?"""
        print("=" * 80)
        print("TEST 2: CONVERGENT ERROR DIGIT DISTRIBUTION (CRITICAL)")
        print("=" * 80)
        print("\nThis is the KEY test from the discovery!")
        print("If errors are uniform ‚Üí œÄ is likely NORMAL")
        print("If errors are non-uniform ‚Üí œÄ might NOT be normal\n")
        
        all_error_digits = []
        error_sources = []
        
        # Analyze errors from convergents
        for i in range(min(50, len(self.convergents))):
            conv = self.convergents[i]
            conv_decimal = Decimal(conv.numerator) / Decimal(conv.denominator)
            
            # Compute error
            error = abs(self.pi_decimal - conv_decimal)
            error_str = str(error)
            
            # Extract digits (skip '0.')
            if '.' in error_str:
                error_digits = error_str.split('.')[1].replace('E', '').replace('-', '').replace('+', '')
            else:
                error_digits = error_str
            
            # Remove leading zeros
            error_digits = error_digits.lstrip('0')
            
            if len(error_digits) > 10:  # Only use significant errors
                all_error_digits.extend(error_digits[:100])  # Take first 100 digits of each error
                error_sources.append({
                    'convergent_num': i,
                    'cf_term': self.cf_terms[i],
                    'error_magnitude': float(error),
                    'error_digits': error_digits[:50]
                })
        
        # Test uniformity of all error digits combined
        if len(all_error_digits) > 100:
            error_digit_str = ''.join(all_error_digits)
            chi_sq = self.chi_square_test(error_digit_str)
            
            print(f"Total error digits collected: {len(error_digit_str):,}")
            print(f"Chi-square: {chi_sq:.4f}")
            print(f"Threshold:  16.919 (95% confidence)")
            print(f"Result: {'‚úì UNIFORM' if chi_sq < 16.919 else '‚úó NON-UNIFORM'}")
            
            # Show distribution
            counts = Counter(error_digit_str)
            expected = len(error_digit_str) / 10
            
            print("\nError digit distribution:")
            for digit in '0123456789':
                count = counts.get(digit, 0)
                pct = (count / len(error_digit_str)) * 100
                deviation = count - expected
                bar = '‚ñà' * int(pct)
                print(f"  {digit}: {count:5} ({pct:5.2f}%) {bar:12} | deviation: {deviation:+6.1f}")
            
            # Show some error examples
            print("\nSample error digit sequences:")
            for src in error_sources[:10]:
                print(f"  CF[{src['convergent_num']:2}] = {src['cf_term']:6} ‚Üí error digits: {src['error_digits'][:30]}...")
            
            # VERDICT
            print("\n" + "‚îÄ" * 80)
            if chi_sq < 16.919:
                print("‚úì‚úì‚úì CONVERGENT ERRORS ARE UNIFORM ‚úì‚úì‚úì")
                print("This STRONGLY suggests œÄ is NORMAL!")
            else:
                print("‚úó‚úó‚úó CONVERGENT ERRORS ARE NON-UNIFORM ‚úó‚úó‚úó")
                print("This suggests œÄ might NOT be normal!")
            print("‚îÄ" * 80 + "\n")
            
            return {'chi_square': chi_sq, 'uniform': chi_sq < 16.919}
        else:
            print("‚ö† Not enough error digits collected\n")
            return None
    
    def test_3_large_cf_term_impact(self):
        """TEST 3: Do large CF terms disrupt uniformity?"""
        print("=" * 80)
        print("TEST 3: LARGE CF TERM IMPACT ON DIGIT DISTRIBUTION")
        print("=" * 80)
        print("\nHypothesis: Large CF terms (like 292) should NOT disrupt uniformity")
        print("if œÄ is normal\n")
        
        # Find large CF terms
        large_terms = [(i, term) for i, term in enumerate(self.cf_terms) if term > 10]
        
        print(f"Found {len(large_terms)} large CF terms (> 10):")
        for i, term in large_terms[:15]:
            print(f"  CF[{i:3}] = {term:6}")
        
        # For each large term, check digit distribution in surrounding region
        print("\nAnalyzing digit distribution around large CF terms...")
        
        results = []
        for i, term in large_terms[:10]:  # Test first 10 large terms
            # Get convergent accuracy
            if i >= len(self.convergents):
                continue
            
            conv = self.convergents[i]
            conv_str = str(Decimal(conv.numerator) / Decimal(conv.denominator))
            
            if '.' in conv_str:
                conv_str = conv_str.split('.')[1]
            
            # Find where convergent matches œÄ
            match_count = 0
            for j in range(min(len(self.pi_str), len(conv_str))):
                if self.pi_str[j] == conv_str[j]:
                    match_count += 1
                else:
                    break
            
            # Get digits in a window around this position
            window_size = 500
            start = max(0, match_count - window_size // 2)
            end = min(len(self.pi_str), match_count + window_size // 2)
            
            window_digits = self.pi_str[start:end]
            
            if len(window_digits) > 100:
                chi_sq = self.chi_square_test(window_digits)
                
                print(f"\n  CF[{i:3}] = {term:6} | accuracy: {match_count:5} digits | window: [{start:6}:{end:6}]")
                print(f"    Chi-square: {chi_sq:.4f} | {'‚úì uniform' if chi_sq < 16.919 else '‚úó non-uniform'}")
                
                results.append({
                    'cf_index': i,
                    'cf_term': term,
                    'accuracy': match_count,
                    'chi_square': chi_sq,
                    'uniform': chi_sq < 16.919
                })
        
        # VERDICT
        print("\n" + "‚îÄ" * 80)
        if results:
            uniform_count = sum(1 for r in results if r['uniform'])
            uniform_pct = (uniform_count / len(results)) * 100
            
            print(f"Uniformity around large CF terms: {uniform_count}/{len(results)} ({uniform_pct:.1f}%)")
            
            if uniform_pct > 80:
                print("‚úì Large CF terms do NOT disrupt uniformity")
                print("This supports normality!")
            else:
                print("‚úó Large CF terms appear to disrupt uniformity")
                print("This challenges normality!")
        print("‚îÄ" * 80 + "\n")
        
        return results
    
    def test_4_gauss_kuzmin_distribution(self):
        """TEST 4: Does œÄ follow Gauss-Kuzmin distribution?"""
        print("=" * 80)
        print("TEST 4: GAUSS-KUZMIN DISTRIBUTION TEST")
        print("=" * 80)
        print("\nFor 'typical' numbers, CF terms follow a known distribution.")
        print("If œÄ follows this, it suggests œÄ is 'normal'.\n")
        
        def gauss_kuzmin_prob(k):
            """Expected probability for CF term k"""
            if k == 0:
                return 0
            return math.log2(1 + 1 / (k * (k + 2)))
        
        # Count actual CF term frequencies
        cf_counts = Counter(self.cf_terms[1:])  # Skip the first term (3)
        total_terms = len(self.cf_terms) - 1
        
        print(f"Analyzing {total_terms} CF terms...\n")
        print(f"{'Term':<6} | {'Expected %':<12} | {'Actual %':<12} | {'Count':<8} | {'Deviation':<12}")
        print("‚îÄ" * 70)
        
        total_deviation = 0
        significant_deviations = []
        
        for k in range(1, 21):
            expected_prob = gauss_kuzmin_prob(k)
            expected_pct = expected_prob * 100
            expected_count = expected_prob * total_terms
            
            actual_count = cf_counts.get(k, 0)
            actual_pct = (actual_count / total_terms) * 100
            
            deviation = abs(actual_pct - expected_pct)
            total_deviation += deviation
            
            status = '‚úì' if deviation < expected_pct * 0.5 else '‚úó'
            
            print(f"{k:<6} | {expected_pct:11.2f}% | {actual_pct:11.2f}% | {actual_count:8} | {deviation:+11.2f}% {status}")
            
            if deviation > expected_pct * 0.5 and k < 15:
                significant_deviations.append((k, deviation, actual_count, expected_count))
        
        # Check for anomalous large terms
        print("\nLarge CF terms (> 20):")
        large_cf = [(i, term) for i, term in enumerate(self.cf_terms) if term > 20]
        for i, term in large_cf[:10]:
            print(f"  CF[{i:3}] = {term:6}")
        
        # VERDICT
        print("\n" + "‚îÄ" * 80)
        avg_deviation = total_deviation / 20
        
        print(f"Average deviation from Gauss-Kuzmin: {avg_deviation:.2f}%")
        
        if avg_deviation < 2.0:
            print("‚úì œÄ CLOSELY follows Gauss-Kuzmin distribution")
            print("This suggests œÄ behaves like a 'typical' irrational number ‚Üí likely NORMAL")
        elif avg_deviation < 5.0:
            print("‚âà œÄ ROUGHLY follows Gauss-Kuzmin distribution")
            print("This is consistent with normality, but with some anomalies")
        else:
            print("‚úó œÄ DEVIATES significantly from Gauss-Kuzmin")
            print("This suggests œÄ might NOT be normal")
        
        if significant_deviations:
            print("\nSignificant deviations:")
            for k, dev, actual, expected in significant_deviations:
                print(f"  Term {k}: deviation {dev:.2f}% (expected ~{expected:.1f}, got {actual})")
        
        print("‚îÄ" * 80 + "\n")
        
        return {'avg_deviation': avg_deviation, 'follows_gk': avg_deviation < 5.0}
    
    def test_5_feynman_convergent_connection(self):
        """TEST 5: Is Feynman point related to convergent boundaries?"""
        print("=" * 80)
        print("TEST 5: FEYNMAN POINT & CONVERGENT BOUNDARY CONNECTION")
        print("=" * 80)
        print("\nHypothesis: Feynman point (999999 at ~762) might be near a convergent boundary\n")
        
        # Find Feynman point
        feynman_pos = self.pi_str.find('999999')
        
        if feynman_pos == -1:
            print("Feynman point not found in available digits\n")
            return None
        
        print(f"Feynman point found at position: {feynman_pos}")
        print(f"Context: ...{self.pi_str[max(0, feynman_pos-10):feynman_pos]}[999999]{self.pi_str[feynman_pos+6:feynman_pos+16]}...")
        
        # Find which convergent has accuracy near this position
        print("\nConvergent accuracies near Feynman point:")
        print(f"{'Convergent':<12} | {'CF Term':<10} | {'Accuracy':<12} | {'Distance to FP':<18}")
        print("‚îÄ" * 60)
        
        close_convergents = []
        
        for i in range(min(30, len(self.convergents))):
            conv = self.convergents[i]
            conv_str = str(Decimal(conv.numerator) / Decimal(conv.denominator))
            
            if '.' in conv_str:
                conv_str = conv_str.split('.')[1]
            
            # Count matching digits
            matches = 0
            for j in range(min(len(self.pi_str), len(conv_str))):
                if self.pi_str[j] == conv_str[j]:
                    matches += 1
                else:
                    break
            
            distance = abs(matches - feynman_pos)
            
            if distance < 200 or i < 15:
                status = '‚≠ê' if distance < 50 else ''
                print(f"{i:<12} | {self.cf_terms[i]:<10} | {matches:<12} | {distance:<18} {status}")
                
                if distance < 100:
                    close_convergents.append((i, self.cf_terms[i], matches, distance))
        
        # VERDICT
        print("\n" + "‚îÄ" * 80)
        if close_convergents:
            closest = min(close_convergents, key=lambda x: x[3])
            print(f"Closest convergent: CF[{closest[0]}] = {closest[1]} (accuracy: {closest[2]}, distance: {closest[3]})")
            
            if closest[3] < 50:
                print("‚úì Feynman point IS near a convergent boundary!")
                print("This suggests it's an error correction artifact ‚Üí supports NORMALITY")
            else:
                print("‚úó Feynman point is NOT particularly close to convergent boundaries")
                print("This suggests it might be a true anomaly ‚Üí challenges normality")
        else:
            print("No convergents found near Feynman point")
        print("‚îÄ" * 80 + "\n")
        
        return close_convergents
    
    def test_6_digit_stability_prediction(self):
        """TEST 6: Can convergents predict stable digit positions?"""
        print("=" * 80)
        print("TEST 6: CONVERGENT PREDICTION OF DIGIT STABILITY")
        print("=" * 80)
        print("\nHypothesis: Large CF terms should correspond to many newly-stable digits\n")
        
        stability_data = []
        
        print(f"{'Conv':<6} | {'CF Term':<10} | {'Stable Digits':<15} | {'New Stable':<12} | {'Pattern':<10}")
        print("‚îÄ" * 70)
        
        prev_stable = 0
        
        for i in range(min(30, len(self.convergents))):
            conv = self.convergents[i]
            conv_str = str(Decimal(conv.numerator) / Decimal(conv.denominator))
            
            if '.' in conv_str:
                conv_str = conv_str.split('.')[1]
            
            stable = 0
            for j in range(min(len(self.pi_str), len(conv_str))):
                if self.pi_str[j] == conv_str[j]:
                    stable += 1
                else:
                    break
            
            new_stable = stable - prev_stable
            cf_term = self.cf_terms[i]
            
            # Pattern: large CF term should ‚Üí many new stable digits
            pattern = '‚≠ê' if (cf_term > 10 and new_stable > 1) else ''
            pattern = '‚ö†' if (cf_term > 10 and new_stable <= 0) else pattern
            
            print(f"{i:<6} | {cf_term:<10} | {stable:<15} | {new_stable:+12} | {pattern:<10}")
            
            stability_data.append({
                'convergent': i,
                'cf_term': cf_term,
                'stable': stable,
                'new_stable': new_stable
            })
            
            prev_stable = stable
        
        # Analyze correlation
        large_terms = [d for d in stability_data if d['cf_term'] > 10]
        
        if large_terms:
            avg_new_stable_large = sum(d['new_stable'] for d in large_terms) / len(large_terms)
            small_terms = [d for d in stability_data if d['cf_term'] <= 10 and d['cf_term'] > 0]
            avg_new_stable_small = sum(d['new_stable'] for d in small_terms) / len(small_terms) if small_terms else 0
            
            print("\n" + "‚îÄ" * 80)
            print(f"Average new stable digits for large CF terms (>10): {avg_new_stable_large:.2f}")
            print(f"Average new stable digits for small CF terms (‚â§10): {avg_new_stable_small:.2f}")
            
            if avg_new_stable_large > avg_new_stable_small * 1.2:
                print("‚úì Large CF terms DO correlate with more stable digits")
                print("This confirms the hypothesis ‚Üí supports the geometric error theory")
            else:
                print("‚úó No clear correlation between CF term size and stability")
                print("This challenges the hypothesis")
            print("‚îÄ" * 80 + "\n")
        
        return stability_data
    
    def generate_final_verdict(self, test_results):
        """Generate final verdict on œÄ's normality"""
        print("\n")
        print("‚ïî" + "‚ïê" * 78 + "‚ïó")
        print("‚ïë" + " " * 25 + "FINAL VERDICT ON œÄ's NORMALITY" + " " * 23 + "‚ïë")
        print("‚ïö" + "‚ïê" * 78 + "‚ïù")
        
        print("\nüìä SUMMARY OF ALL TESTS:\n")
        
        evidence_for_normality = []
        evidence_against_normality = []
        
        # Test 1: Baseline
        if test_results.get('test1'):
            if all(r['uniform'] for r in test_results['test1']):
                evidence_for_normality.append("‚úì Baseline digits are uniformly distributed")
            else:
                evidence_against_normality.append("‚úó Baseline digits show non-uniformity")
        
        # Test 2: Convergent errors (MOST IMPORTANT)
        if test_results.get('test2'):
            if test_results['test2']['uniform']:
                evidence_for_normality.append("‚úì‚úì CONVERGENT ERRORS ARE UNIFORM (KEY FINDING!)")
            else:
                evidence_against_normality.append("‚úó‚úó CONVERGENT ERRORS ARE NON-UNIFORM (KEY FINDING!)")
        
        # Test 3: Large CF terms
        if test_results.get('test3'):
            uniform_pct = sum(1 for r in test_results['test3'] if r['uniform']) / len(test_results['test3']) * 100
            if uniform_pct > 80:
                evidence_for_normality.append("‚úì Large CF terms don't disrupt uniformity")
            else:
                evidence_against_normality.append("‚úó Large CF terms disrupt uniformity")
        
        # Test 4: Gauss-Kuzmin
        if test_results.get('test4'):
            if test_results['test4']['follows_gk']:
                evidence_for_normality.append("‚úì Follows Gauss-Kuzmin distribution")
            else:
                evidence_against_normality.append("‚úó Deviates from Gauss-Kuzmin distribution")
        
        # Test 5: Feynman point
        if test_results.get('test5'):
            if test_results['test5'] and min(c[3] for c in test_results['test5']) < 50:
                evidence_for_normality.append("‚úì Feynman point explained by convergent boundary")
            else:
                evidence_against_normality.append("‚âà Feynman point unexplained (but not decisive)")
        
        print("EVIDENCE FOR NORMALITY:")
        for evidence in evidence_for_normality:
            print(f"  {evidence}")
        
        print("\nEVIDENCE AGAINST NORMALITY:")
        for evidence in evidence_against_normality:
            print(f"  {evidence}")
        
        # Calculate confidence
        total_tests = len(evidence_for_normality) + len(evidence_against_normality)
        confidence = len(evidence_for_normality) / total_tests * 100 if total_tests > 0 else 50
        
        print("\n" + "‚ïê" * 80)
        print("FINAL CONCLUSION:")
        print("‚ïê" * 80 + "\n")
        
        # Weight Test 2 heavily
        if test_results.get('test2'):
            if test_results['test2']['uniform']:
                print("üéØ Based on the CRITICAL discovery that œÄ's digits encode convergent errors,")
                print("   and the fact that these errors ARE UNIFORMLY DISTRIBUTED:")
                print()
                print("   ‚úì‚úì‚úì œÄ IS ALMOST CERTAINLY NORMAL ‚úì‚úì‚úì")
                print()
                print(f"   Confidence: {confidence:.1f}%")
                print()
                print("   REASONING:")
                print("   ‚Ä¢ Convergent errors are uniform (Test 2) ‚Üê MOST IMPORTANT")
                print("   ‚Ä¢ Baseline digits are uniform (Test 1)")
                print("   ‚Ä¢ The geometric error encoding theory is VALIDATED")
                print("   ‚Ä¢ Therefore: œÄ's digits should be normal")
            else:
                print("üéØ Based on the CRITICAL discovery that œÄ's digits encode convergent errors,")
                print("   and the fact that these errors are NON-UNIFORM:")
                print()
                print("   ‚úó‚úó‚úó œÄ MIGHT NOT BE NORMAL ‚úó‚úó‚úó")
                print()
                print(f"   Confidence: {100 - confidence:.1f}%")
                print()
                print("   REASONING:")
                print("   ‚Ä¢ Convergent errors are NON-uniform (Test 2) ‚Üê CRITICAL FINDING")
                print("   ‚Ä¢ This suggests hidden structure in the error generation")
                print("   ‚Ä¢ The geometric error encoding might create patterns")
                print("   ‚Ä¢ Therefore: œÄ might not have uniform digit distribution")
        else:
            print("‚ö† Insufficient data to make a conclusive determination")
            print(f"  Current evidence leans: {'NORMAL' if confidence > 50 else 'NON-NORMAL'}")
            print(f"  Confidence: {max(confidence, 100-confidence):.1f}%")
        
        print("\n" + "‚ïê" * 80)
        print()
        print("üìù NOTE: This is based on finite data. True normality requires infinite analysis.")
        print("   However, the convergent error approach is a NEW and potentially PROVABLE method!")
        print()
        print("‚ïê" * 80 + "\n")
    
    def run_all_tests(self):
        """Run complete test suite"""
        test_results = {}
        
        # Compute continued fraction
        self.compute_continued_fraction(max_terms=100)
        self.compute_all_convergents()
        
        # Run all tests
        test_results['test1'] = self.test_1_baseline_digit_distribution()
        test_results['test2'] = self.test_2_convergent_error_distribution()
        test_results['test3'] = self.test_3_large_cf_term_impact()
        test_results['test4'] = self.test_4_gauss_kuzmin_distribution()
        test_results['test5'] = self.test_5_feynman_convergent_connection()
        test_results['test6'] = self.test_6_digit_stability_prediction()
        
        # Generate final verdict
        self.generate_final_verdict(test_results)
        
        return test_results


def main():
    """Main execution"""
    print("\nüöÄ Starting œÄ normality analysis using convergent error theory...\n")
    
    try:
        # Create tester instance
        tester = PiNormalityTester(pi_file='pi_digits.txt', num_digits=100000)
        
        # Run all tests
        results = tester.run_all_tests()
        
        print("\n‚úì Analysis complete!")
        print("\nTo extend this analysis:")
        print("  1. Increase num_digits to 1,000,000+ for more confidence")
        print("  2. Compute more CF terms (max_terms=1000+)")
        print("  3. Analyze cross-base behavior (binary, hex)")
        print("  4. Study the mathematical properties of error distributions")
        
    except FileNotFoundError:
        print("‚ùå Error: pi_digits.txt not found!")
        print("   Please ensure the file exists in the current directory.")
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()